import mss
import numpy as np
import sounddevice as sd
import wave
import threading
import time
from moviepy import editor  # æ–°ç‰ˆ moviepy ç”¨æ³•
import keyboard
import cv2
from datetime import datetime
import os

# === éŒ„å½±åƒæ•¸è¨­å®š ===
FPS = 90                # æ¯ç§’å½±æ ¼æ•¸ (è¶Šé«˜ç•«é¢è¶Šé †æš¢ï¼Œä½†æª”æ¡ˆè¶Šå¤§)
BITRATE = "8000k"       # å½±ç‰‡è¼¸å‡ºä½å…ƒçŽ‡ (ä¾‹å¦‚: 4000kã€6000kã€8000k)

# === è‡ªå‹•å‘½å ===
now = datetime.now()
timestamp = now.strftime("%Y-%m-%d %H-%M-%S")

VIDEO_FILENAME = f"{timestamp}_temp.mp4"
AUDIO_FILENAME = f"{timestamp}_audio.wav"
OUTPUT_FILENAME = f"{timestamp}.mp4"

# === éŸ³è¨Šè¨­å®š ===
samplerate = 44100
channels = 2

# === å…¨åŸŸæŽ§åˆ¶æ——æ¨™ ===
stop_flag = False

# === éŒ„éŸ³å‡½å¼ ===
def record_audio():
    global stop_flag
    print("ðŸŽ™ï¸ é–‹å§‹éŒ„éŸ³...")
    audio_data = []

    def callback(indata, frames, time_info, status):
        if stop_flag:
            raise sd.CallbackStop()
        audio_data.append(indata.copy())

    with sd.InputStream(samplerate=samplerate, channels=channels, dtype='int16', callback=callback):
        while not stop_flag:
            sd.sleep(100)

    # åˆä½µéŸ³è¨Šè³‡æ–™
    audio_array = np.concatenate(audio_data, axis=0)
    with wave.open(AUDIO_FILENAME, 'wb') as wf:
        wf.setnchannels(channels)
        wf.setsampwidth(2)
        wf.setframerate(samplerate)
        wf.writeframes(audio_array.tobytes())
    print("âœ… éŒ„éŸ³å®Œæˆã€‚")

# === éŒ„èž¢å¹•å‡½å¼ ===
def record_screen():
    global stop_flag
    print("ðŸ–¥ï¸ é–‹å§‹éŒ„å½±...")
    sct = mss.mss()
    monitor = sct.monitors[1]
    frames = []
    frame_interval = 1.0 / FPS

    while not stop_flag:
        start_time = time.time()
        img = np.array(sct.grab(monitor))
        frame = img[:, :, :3]  # ç§»é™¤ alpha é€šé“
        frames.append(frame)

        # åµæ¸¬é€£çºŒæŒ‰ä¸‹ [ + ] åœæ­¢éŒ„å½±
        if keyboard.is_pressed("[") and keyboard.is_pressed("]"):
            start = time.time()
            while keyboard.is_pressed("[") and keyboard.is_pressed("]"):
                if time.time() - start >= 1.0:
                    stop_flag = True
                    break
            if stop_flag:
                break

        # æŽ§åˆ¶éŒ„å½±é »çŽ‡
        elapsed = time.time() - start_time
        if elapsed < frame_interval:
            time.sleep(frame_interval - elapsed)

    print("ðŸ›‘ éŒ„å½±å®Œæˆï¼Œæ­£åœ¨å„²å­˜å½±ç‰‡...")
    height, width, _ = frames[0].shape
    fourcc = cv2.VideoWriter_fourcc(*"mp4v")
    out = cv2.VideoWriter(VIDEO_FILENAME, fourcc, FPS, (width, height))
    for f in frames:
        out.write(f)
    out.release()
    print("âœ… å½±ç‰‡å„²å­˜å®Œæˆã€‚")

# === ä¸»ç¨‹å¼ ===
if __name__ == "__main__":
    print("ðŸŽ¬ éŒ„å½±ç¨‹å¼å•Ÿå‹•ä¸­...")
    print("æç¤ºï¼šåŒæ™‚æŒ‰ä¸‹ [ å’Œ ] ç´„ 1 ç§’å¯çµæŸéŒ„å½±ã€‚")

    t1 = threading.Thread(target=record_audio)
    t2 = threading.Thread(target=record_screen)

    t1.start()
    t2.start()

    t1.join()
    t2.join()

    print("ðŸ”„ åˆä½µè²éŸ³èˆ‡ç•«é¢ä¸­...")
    video_clip = editor.VideoFileClip(VIDEO_FILENAME)
    audio_clip = editor.AudioFileClip(AUDIO_FILENAME)
    final_clip = video_clip.set_audio(audio_clip)

    final_clip.write_videofile(
        OUTPUT_FILENAME,
        codec='libx264',
        audio_codec='aac',
        bitrate=BITRATE,
        fps=FPS
    )

    # è‡ªå‹•åˆªé™¤æš«å­˜æª”æ¡ˆ
    if os.path.exists(VIDEO_FILENAME):
        os.remove(VIDEO_FILENAME)
    if os.path.exists(AUDIO_FILENAME):
        os.remove(AUDIO_FILENAME)

    print("ðŸŽ‰ å®Œæˆï¼è¼¸å‡ºæª”æ¡ˆï¼š", OUTPUT_FILENAME)
